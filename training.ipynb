{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import generic libraries\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import random\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Import sentence transformer libraries\n",
    "from sentence_transformers import SentenceTransformer,util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The randomly selected question is:  What are the advantages and disadvantages of bag of words\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "file = './deeplearning_questions.csv'\n",
    "df = pd.read_csv(file)\n",
    "\n",
    "# Basic data cleansing\n",
    "df.dropna()\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Random question selection (source question)\n",
    "'''this will be the source question for which we will find similar questions'''\n",
    "src_q = random.choice(df['DESCRIPTION'])\n",
    "idx = df.index[df['DESCRIPTION'] == src_q][0]\n",
    "\n",
    "# removing the above question from the original dataframe & reset it\n",
    "df.drop(idx, inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(f\"The randomly selected question is: {src_q}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1.18k/1.18k [00:00<00:00, 293kB/s]\n",
      "Downloading: 100%|██████████| 190/190 [00:00<00:00, 27.2kB/s]\n",
      "Downloading: 100%|██████████| 10.6k/10.6k [00:00<00:00, 964kB/s]\n",
      "Downloading: 100%|██████████| 612/612 [00:00<00:00, 205kB/s]\n",
      "Downloading: 100%|██████████| 116/116 [00:00<00:00, 28.1kB/s]\n",
      "Downloading: 100%|██████████| 39.3k/39.3k [00:00<00:00, 64.0kB/s]\n",
      "Downloading: 100%|██████████| 90.9M/90.9M [00:10<00:00, 8.99MB/s]\n",
      "Downloading: 100%|██████████| 53.0/53.0 [00:00<00:00, 13.3kB/s]\n",
      "Downloading: 100%|██████████| 112/112 [00:00<00:00, 16.0kB/s]\n",
      "Downloading: 100%|██████████| 466k/466k [00:01<00:00, 322kB/s]  \n",
      "Downloading: 100%|██████████| 350/350 [00:00<00:00, 49.8kB/s]\n",
      "Downloading: 100%|██████████| 13.2k/13.2k [00:00<00:00, 2.64MB/s]\n",
      "Downloading: 100%|██████████| 232k/232k [00:04<00:00, 55.1kB/s] \n",
      "Downloading: 100%|██████████| 349/349 [00:00<00:00, 49.9kB/s]\n"
     ]
    }
   ],
   "source": [
    "# Instantiate model\n",
    "'''using all-MiniLM-L6-v2 model'''\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "# Compute embedding for source question\n",
    "embed_src = model.encode(src_q, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over the remaining question list\n",
    "score = []\n",
    "for q in df['DESCRIPTION']:\n",
    "    embed_trgt = model.encode(q,convert_to_tensor=True)\n",
    "    semanticSearch = util.semantic_search(embed_src, embed_trgt)\n",
    "    semanticSearch_score = semanticSearch[0][0]['score']\n",
    "    score.append(float(\"{:.4f}\".format(semanticSearch_score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the new 'SCORE' column to the existing dataframe\n",
    "df['SCORE'] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>SCORE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83</td>\n",
       "      <td>What is bag of words How we can use it for te...</td>\n",
       "      <td>0.6405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80</td>\n",
       "      <td>What are some advantages of using character e...</td>\n",
       "      <td>0.5278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82</td>\n",
       "      <td>Would you prefer gradient boosting trees mode...</td>\n",
       "      <td>0.5173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41</td>\n",
       "      <td>How large should be N for our bag of words wh...</td>\n",
       "      <td>0.5064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>78</td>\n",
       "      <td>What are word embeddings Why are they useful</td>\n",
       "      <td>0.4982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>8</td>\n",
       "      <td>What is the Computational Graph</td>\n",
       "      <td>-0.0328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>55</td>\n",
       "      <td>How to handle exploding gradient problem</td>\n",
       "      <td>-0.0402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>69</td>\n",
       "      <td>What is the range of activation functions</td>\n",
       "      <td>-0.0402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>74</td>\n",
       "      <td>What is RNN and How does an RNN work</td>\n",
       "      <td>-0.0547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>48</td>\n",
       "      <td>How to handle dying node problems in case of ...</td>\n",
       "      <td>-0.0818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID                                        DESCRIPTION   SCORE\n",
       "0    83   What is bag of words How we can use it for te...  0.6405\n",
       "1    80   What are some advantages of using character e...  0.5278\n",
       "2    82   Would you prefer gradient boosting trees mode...  0.5173\n",
       "3    41   How large should be N for our bag of words wh...  0.5064\n",
       "4    78       What are word embeddings Why are they useful  0.4982\n",
       "..   ..                                                ...     ...\n",
       "105   8                    What is the Computational Graph -0.0328\n",
       "106  55           How to handle exploding gradient problem -0.0402\n",
       "107  69          What is the range of activation functions -0.0402\n",
       "108  74               What is RNN and How does an RNN work -0.0547\n",
       "109  48   How to handle dying node problems in case of ... -0.0818\n",
       "\n",
       "[110 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort & view the new dataframe\n",
    "df.sort_values(by='SCORE', inplace=True, ascending=False)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 questions similar to >>  What are the advantages and disadvantages of bag of words\n",
      "\n",
      "╒═════╤════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════╕\n",
      "│   # │ SimilarQuestions                                                                                                       │\n",
      "╞═════╪════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════╡\n",
      "│   0 │ What is bag of words How we can use it for text vectorization                                                          │\n",
      "├─────┼────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "│   1 │ What are some advantages of using character embeddings instead of word embeddings                                      │\n",
      "├─────┼────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "│   2 │ Would you prefer gradient boosting trees model or logistic regression when doing text classification with bag of words │\n",
      "├─────┼────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "│   3 │ How large should be N for our bag of words when using N-grams                                                          │\n",
      "├─────┼────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "│   4 │ What are word embeddings Why are they useful                                                                           │\n",
      "├─────┼────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "│   5 │ For infrequent/rare words which among CBOW and SkipGram should be used for wordvec training                            │\n",
      "├─────┼────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "│   6 │ Why do we remove stop words When do we not remove them                                                                 │\n",
      "├─────┼────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "│   7 │ How is wordvec different from Glove                                                                                    │\n",
      "├─────┼────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "│   8 │ How is fastText different from wordvec                                                                                 │\n",
      "├─────┼────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "│   9 │ what is WordVec                                                                                                        │\n",
      "╘═════╧════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════╛\n"
     ]
    }
   ],
   "source": [
    "print(f\"Top 10 questions similar to >> {src_q}\\n\")\n",
    "print(tabulate(df[['DESCRIPTION']].head(10), headers=['#','SimilarQuestions'], tablefmt='fancy_grid'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python ('nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": ""
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "25a19fbe0a9132dfb9279d48d161753c6352f8f9478c2e74383d340069b907c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
